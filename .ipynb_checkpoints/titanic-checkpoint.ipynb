{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "## Bèta excellent vrije opdracht\n",
    "### Revius Lyceum Doorn\n",
    "#### Carlo Jacobs 5-03-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Introduction\n",
    "In this notebook we will be diving into the inner workings of a neural network. We will be creating a machine learning model using python 3 and we will train this model on a dataset I acquired from [this](https://www.kaggle.com/c/titanic) kaggle competition. Kaggle is a free online datascience platform that hosts machine learning competitions with datasets provided by companies or organizations. More information can be found on [the kaggle website](https://www.kaggle.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requirements\n",
    "1. A working computer\n",
    "2. The dataset (download link above)\n",
    "2. Python3\n",
    "3. Numpy\n",
    "4. Pandas\n",
    "5. Tensorflow\n",
    "6. Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How does a neural network work?\n",
    "\n",
    "### The architecture of a neural network\n",
    "\n",
    "A **neural network** is one of the most popular tools that is used in machine learning today, it can accurately predict things after being trained on a large dataset. A neural network (NN) consists of layers. Each of these layers contain **neurons**. These neurons are associated an activation determined by their inputs and other variables. An NN is based on a collection of these neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal from one neuron to another. A neuron that receives a signal can process it and then signal additional neurons connected to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Neural network](https://upload.wikimedia.org/wikipedia/commons/6/60/ArtificialNeuronModel_english.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each neuron has some quantaties associated to it. The input, is given by $$p_j\\left(t\\right) = \\sum_{i} o\\left(t\\right)_i w_{ij} + w_{0j}.$$ Where,\n",
    "- $p_j\\left(t\\right)$ is the input of the neuron.\n",
    "- $i$ is the index summing over all the predecessor neurons.\n",
    "- $o_i\\left(t\\right)$ is the output from neuron's predecessor.\n",
    "- $w_{ij}$ is the weight associated with the neuron.\n",
    "- $w_{0j}$ is the bias associated with the neuron.\n",
    "\n",
    "To each neuron there is associated an activation function $f$ that is dependent on $p_j$. This function maps the neurons input to a value that we call its **activation** $a_j$. Some commonly used activation function are:\n",
    "\n",
    "- Sigmoid: $f\\left(p\\right) = \\frac{1}{1 + e^{-p}}.$\n",
    "- ReLU: $f\\left(p\\right) = \\text{max}\\left(0, p\\right).$\n",
    "- Hyperbolic tangent: $f\\left(p\\right) = \\tanh \\left(p\\right).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Learing of the network\n",
    "\n",
    "The NN learns to accurately perform its task by constantly trying to minimize a **cost function**. Given a specific task to solve, and a class of functions $F$, learning means using a set of observations to find $f^{*}\\in F$ which solves the task in some optimal sense. This entails defining a cost function $C:F\\rightarrow \\mathbb {R}$  such that, for the optimal solution $f^{*},  C(f^{*})\\leq C(f)\\, \\forall f\\in F$. This can be done by a process called backpropagation. Backpropagation is a method that calculates the gradient of the cost function with respect to the weights in the NN. The weights are then updated according to this gradient. One example of backpropagation is **Stochastic Gradient Descent** and it can be described by the following equation $$w_{ij}\\left(t+1\\right) = w_{ij}\\left(t\\right) + \\eta \\frac{\\partial C}{\\partial w_{ij}} + \\zeta \\left(t\\right).$$ Where,\n",
    "- $\\eta$ is the learning rate.\n",
    "- $C$ the cost function.\n",
    "- $\\zeta \\left(t\\right)$ a stochastic term.\n",
    "\n",
    "Using the method of backpropagtion, the network can update its weigths to minimize the cost function and get optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adjusting the degrees of freedom of a neural network\n",
    "\n",
    "This type of neural network has multiple degrees of freedom that can be adjusted in order to increase the performance or accuracy of a neural network. Some examples are\n",
    "- The learning rate.\n",
    "- The number of layers in the network.\n",
    "- The activation function of each layer.\n",
    "- The cost funciton.\n",
    "- The sample size of training data.\n",
    "\n",
    "There is no fixed rulebook on how to set up these parameters. There are only certain estimations that suggest a certain amount of layers or a certain learning rate dependent on (for example) your sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # Linear algebra\n",
    "import pandas as pd # Reading files\n",
    "import tensorflow as tf # Machine learning\n",
    "from tensorflow import keras # Machine learing\n",
    "import matplotlib.pyplot as plt # Visualizing data\n",
    "import math # Mathematics\n",
    "\n",
    "# Making sure matplotlib works\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysing the shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our data consists of the following columns:\n",
    "0. **PassengerId**: (int)\n",
    "1. **Survived**: Survived or Not (int)\n",
    "2. **Pclass**: Class of Travel \n",
    "3. **Name**: Name of Passenger\n",
    "4. **Sex**: Gender\n",
    "5. **Age**: Age of Passengers\n",
    "6. **SibSp**: Number of Sibling/Spouse aboard\n",
    "7. **Parch**: Number of Parent/Child aboard\n",
    "8. **Ticket**: Ticket number\n",
    "9. **Fare**: Price payed by passenger\n",
    "10. **Cabin**: Cabin number\n",
    "11. **Embarked**: The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here we load the `.csv` into our script using the `pandas` library, this creates a `pandas dataframe` which makes it easy for us to viaulize and manipulate the data. Let's do a quick visualization of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  \n",
       "0        0         A/5 21171    7.2500          NaN        S  \n",
       "1        0          PC 17599   71.2833          C85        C  \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3        0            113803   53.1000         C123        S  \n",
       "4        0            373450    8.0500          NaN        S  \n",
       "5        0            330877    8.4583          NaN        Q  \n",
       "6        0             17463   51.8625          E46        S  \n",
       "7        1            349909   21.0750          NaN        S  \n",
       "8        2            347742   11.1333          NaN        S  \n",
       "9        0            237736   30.0708          NaN        C  \n",
       "10       1           PP 9549   16.7000           G6        S  \n",
       "11       0            113783   26.5500         C103        S  \n",
       "12       0         A/5. 2151    8.0500          NaN        S  \n",
       "13       5            347082   31.2750          NaN        S  \n",
       "14       0            350406    7.8542          NaN        S  \n",
       "15       0            248706   16.0000          NaN        S  \n",
       "16       1            382652   29.1250          NaN        Q  \n",
       "17       0            244373   13.0000          NaN        S  \n",
       "18       0            345763   18.0000          NaN        S  \n",
       "19       0              2649    7.2250          NaN        C  \n",
       "20       0            239865   26.0000          NaN        S  \n",
       "21       0            248698   13.0000          D56        S  \n",
       "22       0            330923    8.0292          NaN        Q  \n",
       "23       0            113788   35.5000           A6        S  \n",
       "24       1            349909   21.0750          NaN        S  \n",
       "25       5            347077   31.3875          NaN        S  \n",
       "26       0              2631    7.2250          NaN        C  \n",
       "27       2             19950  263.0000  C23 C25 C27        S  \n",
       "28       0            330959    7.8792          NaN        Q  \n",
       "29       0            349216    7.8958          NaN        S  \n",
       "..     ...               ...       ...          ...      ...  \n",
       "861      0             28134   11.5000          NaN        S  \n",
       "862      0             17466   25.9292          D17        S  \n",
       "863      2          CA. 2343   69.5500          NaN        S  \n",
       "864      0            233866   13.0000          NaN        S  \n",
       "865      0            236852   13.0000          NaN        S  \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
       "867      0          PC 17590   50.4958          A24        S  \n",
       "868      0            345777    9.5000          NaN        S  \n",
       "869      1            347742   11.1333          NaN        S  \n",
       "870      0            349248    7.8958          NaN        S  \n",
       "871      1             11751   52.5542          D35        S  \n",
       "872      0               695    5.0000  B51 B53 B55        S  \n",
       "873      0            345765    9.0000          NaN        S  \n",
       "874      0         P/PP 3381   24.0000          NaN        C  \n",
       "875      0              2667    7.2250          NaN        C  \n",
       "876      0              7534    9.8458          NaN        S  \n",
       "877      0            349212    7.8958          NaN        S  \n",
       "878      0            349217    7.8958          NaN        S  \n",
       "879      1             11767   83.1583          C50        C  \n",
       "880      1            230433   26.0000          NaN        S  \n",
       "881      0            349257    7.8958          NaN        S  \n",
       "882      0              7552   10.5167          NaN        S  \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
       "885      5            382652   29.1250          NaN        Q  \n",
       "886      0            211536   13.0000          NaN        S  \n",
       "887      0            112053   30.0000          B42        S  \n",
       "888      2        W./C. 6607   23.4500          NaN        S  \n",
       "889      0            111369   30.0000         C148        C  \n",
       "890      0            370376    7.7500          NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reshaping the data\n",
    "\n",
    "We need to do some reshaping in order to make the data suitable for our neural network.\n",
    "1. A lot of cabin number are undetermined, so we leave them out.\n",
    "2. The ticket contains letters, which are hard to parse, so we leave them out.\n",
    "3. We don't need the name.\n",
    "4. The sex needs to be converted from \"male\" and \"female\" to 0 and 1.\n",
    "5. The Embarked port needs to be converted from \"C\", \"S\" and \"Q\" to 0, 1 and 2.\n",
    "6. Remove the passenger id.\n",
    "7. Removing any NaN's (Not a Number)\n",
    "\n",
    "After the reshaping of the data, the predicitons of our neural network will be based on:\n",
    "0. Pclass\n",
    "1. Sex\n",
    "2. Age\n",
    "3. SibSp\n",
    "4. Parch\n",
    "5. Fare\n",
    "6. Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Converting to a numpy array\n",
    "In order to manipulate our data we convert it to a numpy array to make it easy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to np array\n",
    "train_data = np.array(train_df)\n",
    "# We have 891 rows each containing 12 datapoints\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can see that we have 891 entries each containing 12 datapoints. We can create a function that will take in our data and reshape it so it is suitable for a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def reshape_data(data, parameter):\n",
    "    \"\"\"Function for reshaping the data\"\"\"\n",
    "    bias = 0\n",
    "    if parameter == \"train\":\n",
    "        pass\n",
    "    elif parameter == \"test\":\n",
    "        bias = -1\n",
    "    # Convert data\n",
    "    for i in range(len(data)):\n",
    "        person = data[i]\n",
    "        # Convert sex from \"male\" and \"female\" to 0 and 1\n",
    "        if person[4 + bias] == \"male\":\n",
    "            data[i][4 + bias] = 0\n",
    "        elif person[4 + bias] == \"female\":\n",
    "            data[i][4 + bias] = 1\n",
    "        else:\n",
    "            print(\"Unidentified sex, changing to male. Index: \", i)\n",
    "            data[i][4] = 0\n",
    "        # Convert embarked port from \"C\", \"S\" and \"Q\" to 0, 1 and 2.\n",
    "        if person[11 + bias] == \"C\":\n",
    "            data[i][11 + bias] = 0\n",
    "        elif person[11 + bias] == \"S\":\n",
    "            data[i][11 + bias] = 1\n",
    "        elif person[11 + bias] == \"Q\":\n",
    "            data[i][11 + bias] = 2\n",
    "        else:\n",
    "            print(\"Unidentified port, changing to C. Index: \", i)\n",
    "            data[i][11 + bias] = 0\n",
    "    \n",
    "    # Dropping the name, ticket and cabin column\n",
    "    data = np.delete(data, [0, 3 + bias, 8 + bias, 10 + bias], 1)\n",
    "    \n",
    "    # Remove all NaN's in our dataset and replace them with 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if np.isnan(data[i][j]):\n",
    "                data[i][j] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "After the reshaping of the data, we get a much more suitable dataset containing only numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidentified port, changing to C. Index:  61\n",
      "Unidentified port, changing to C. Index:  829\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2   3  4  5        6  7\n",
       "0    0  3  0  22  1  0     7.25  1\n",
       "1    1  1  1  38  1  0  71.2833  0\n",
       "2    1  3  1  26  0  0    7.925  1\n",
       "3    1  1  1  35  1  0     53.1  1\n",
       "4    0  3  0  35  0  0     8.05  1\n",
       "5    0  3  0   0  0  0   8.4583  2\n",
       "6    0  1  0  54  0  0  51.8625  1\n",
       "7    0  3  0   2  3  1   21.075  1\n",
       "8    1  3  1  27  0  2  11.1333  1\n",
       "9    1  2  1  14  1  0  30.0708  0\n",
       "10   1  3  1   4  1  1     16.7  1\n",
       "11   1  1  1  58  0  0    26.55  1\n",
       "12   0  3  0  20  0  0     8.05  1\n",
       "13   0  3  0  39  1  5   31.275  1\n",
       "14   0  3  1  14  0  0   7.8542  1\n",
       "15   1  2  1  55  0  0       16  1\n",
       "16   0  3  0   2  4  1   29.125  2\n",
       "17   1  2  0   0  0  0       13  1\n",
       "18   0  3  1  31  1  0       18  1\n",
       "19   1  3  1   0  0  0    7.225  0\n",
       "20   0  2  0  35  0  0       26  1\n",
       "21   1  2  0  34  0  0       13  1\n",
       "22   1  3  1  15  0  0   8.0292  2\n",
       "23   1  1  0  28  0  0     35.5  1\n",
       "24   0  3  1   8  3  1   21.075  1\n",
       "25   1  3  1  38  1  5  31.3875  1\n",
       "26   0  3  0   0  0  0    7.225  0\n",
       "27   0  1  0  19  3  2      263  1\n",
       "28   1  3  1   0  0  0   7.8792  2\n",
       "29   0  3  0   0  0  0   7.8958  1\n",
       "..  .. .. ..  .. .. ..      ... ..\n",
       "861  0  2  0  21  1  0     11.5  1\n",
       "862  1  1  1  48  0  0  25.9292  1\n",
       "863  0  3  1   0  8  2    69.55  1\n",
       "864  0  2  0  24  0  0       13  1\n",
       "865  1  2  1  42  0  0       13  1\n",
       "866  1  2  1  27  1  0  13.8583  0\n",
       "867  0  1  0  31  0  0  50.4958  1\n",
       "868  0  3  0   0  0  0      9.5  1\n",
       "869  1  3  0   4  1  1  11.1333  1\n",
       "870  0  3  0  26  0  0   7.8958  1\n",
       "871  1  1  1  47  1  1  52.5542  1\n",
       "872  0  1  0  33  0  0        5  1\n",
       "873  0  3  0  47  0  0        9  1\n",
       "874  1  2  1  28  1  0       24  0\n",
       "875  1  3  1  15  0  0    7.225  0\n",
       "876  0  3  0  20  0  0   9.8458  1\n",
       "877  0  3  0  19  0  0   7.8958  1\n",
       "878  0  3  0   0  0  0   7.8958  1\n",
       "879  1  1  1  56  0  1  83.1583  0\n",
       "880  1  2  1  25  0  1       26  1\n",
       "881  0  3  0  33  0  0   7.8958  1\n",
       "882  0  3  1  22  0  0  10.5167  1\n",
       "883  0  2  0  28  0  0     10.5  1\n",
       "884  0  3  0  25  0  0     7.05  1\n",
       "885  0  3  1  39  0  5   29.125  2\n",
       "886  0  2  0  27  0  0       13  1\n",
       "887  1  1  1  19  0  0       30  1\n",
       "888  0  3  1   0  1  2    23.45  1\n",
       "889  1  1  0  26  0  0       30  0\n",
       "890  0  3  0  32  0  0     7.75  2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = reshape_data(train_data, \"train\")\n",
    "pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The new structure of our dataset:\n",
    "0. **Survived**: Survived or Not (int)\n",
    "3. **Pclass**: Class of Travel (int)\n",
    "5. **Sex**: Gender (int)\n",
    "6. **Age**: Age of Passengers (float)\n",
    "7. **SibSp**: Number of Sibling/Spouse aboard (int)\n",
    "8. **Parch**: Number of Parent/Child aboard (int)\n",
    "10. **Fare**: Price payed by passenger (float)\n",
    "12. **Embarked**: The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown (int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analyzing the data\n",
    "Using the `matplotlib` libraby we imported above, we can graph, analyze and visualize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Genders of survivors')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(17, 5))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "# Plot the number of the survivors and casualties\n",
    "unique, counts = np.unique([x[0] for x in train_data], return_counts=True)\n",
    "ax1.bar([0, 1], [549, 342], align=\"center\")\n",
    "ax1.set_xticks([0, 1])\n",
    "ax1.set_title(\"Survivors and casualties\")\n",
    "ax1.set_xticklabels((\"Casualties\", \"Survivors\"))\n",
    "\n",
    "# Plot the genders of survivors\n",
    "num_male_survivors = 0\n",
    "num_female_survivors = 0\n",
    "num_survivors = 0\n",
    "for person in train_data:\n",
    "    if person[0] == 1:\n",
    "        num_survivors += 1\n",
    "        if person[2] == 0:\n",
    "            num_male_survivors += 1\n",
    "        elif person[2] == 1:\n",
    "            num_female_survivors += 1\n",
    "\n",
    "percent_male = np.round(num_male_survivors / num_survivors * 100)\n",
    "percent_female = np.round(num_female_survivors / num_survivors * 100)\n",
    "            \n",
    "ax2.pie([109, 233], labels=[f\"{percent_male}% Female\", f\"{percent_female}% Male\"], colors=[\"pink\", \"lightblue\"])\n",
    "ax2.set_title(\"Genders of survivors\")\n",
    "\n",
    "# Plot the number of people in each class\n",
    "unique, counts = np.unique([x[1] for x in train_data], return_counts=True)\n",
    "ax3.bar([1, 2, 3], [counts[0], counts[1], counts[2]], align=\"center\", color=\"orange\")\n",
    "ax3.set_xticks([1, 2, 3])\n",
    "ax3.set_title(\"Number of people in each class\")\n",
    "ax3.set_xticklabels([\"First class\", \"Second class\", \"Third class\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preparing the data for training\n",
    "We need to split our training data into input and output. The input will be everything except for the 'survived' column. The output will contain only this column. This way, we can train our network to predict wether or not a person on the titanic would have been likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def split_training_data(data):\n",
    "    \"\"\"Splits training data into input and output\"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    # Itterate over the data\n",
    "    for item in data:\n",
    "        # Add the survivor datapoint to the array\n",
    "        if item[0] == 0:\n",
    "            y.append([0, 1])\n",
    "        else:\n",
    "            y.append([1, 0])\n",
    "        item = np.delete(item, 0)\n",
    "        x.append(item)\n",
    "    return (np.array(x), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = split_training_data(train_data)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can see that we now have two arrays. On with 891 entries of 7 datapoints, this is the input data, and the other with 891 entries of 2 datapoints, this is the output data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the model\n",
    "We will be using the [keras](https://keras.io/) library to build our neural network. First, we need to construct a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(445, activation=tf.nn.relu, input_shape=(7,)))\n",
    "model.add(keras.layers.Dense(100, activation=tf.nn.sigmoid))\n",
    "model.add(keras.layers.Dense(50, activation=tf.nn.sigmoid))\n",
    "model.add(keras.layers.Dense(2, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Layers\n",
    "This function creates an instance `Sequential` model using the `keras` library built into `tensorflow`. It adds two layers to the model:\n",
    "1. A `Dense` layer containing 445 neurons with a `ReLU` activation function and an inputshape of 7.\n",
    "2. A `Dense` layers containing 100 neurons with a `sigmoid` activation function.\n",
    "2. Another `Dense` layers containing 50 neurons with a `sigmoid` activation function.\n",
    "3. A `Dense` layer containing 2 neurons with a `Softmax` activation function.\n",
    "\n",
    "### Dimensions\n",
    "It is very important that the initial input shape matches the dimensions of the input data, in this case this shape would be 7. It is also important that the number of neurons in the last/output layer of the network matches the dimensions of the output data. In this case 2.\n",
    "\n",
    "### Activation functions\n",
    "The ReLU, which we use in the first layer of our network, is an activation function defined as the positive part of its argument:\n",
    "$$f(x) = max\\left(0,x\\right)$$\n",
    "\n",
    "The Softmax activation function, which we use in our second layer, takes an un-normalized vector (in this case the vector form of the second `Dense` layer), and normalizes it into a probability distribution. That is, prior to applying softmax, some vector elements could be negative, or greater than one; and might not sum to 1; but after applying softmax, each element $x_{i}$ is in the interval $\\left[0,1\\right]$, and $\\sum _{i}x_{i}=1.$ The general softmax function is of the form\n",
    "\n",
    "$$\\sigma (\\mathbf {z} )_{j}={\\frac {e^{z_{j}}}{\\sum _{k=1}^{K}e^{z_{k}}}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compiling the model\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
    "\n",
    "- Loss function —This measures how accurate the model is during training. We want to minimize this function to \"steer\" the model in the right direction.\n",
    "- Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
    "- Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training the model\n",
    "We can now train our model using the `train_x` and `train_y` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "891/891 [==============================] - 1s 957us/sample - loss: 0.2296\n",
      "Epoch 2/30\n",
      "891/891 [==============================] - 0s 233us/sample - loss: 0.2123\n",
      "Epoch 3/30\n",
      "891/891 [==============================] - 0s 233us/sample - loss: 0.2057\n",
      "Epoch 4/30\n",
      "891/891 [==============================] - 0s 235us/sample - loss: 0.2025\n",
      "Epoch 5/30\n",
      "891/891 [==============================] - 0s 222us/sample - loss: 0.1975\n",
      "Epoch 6/30\n",
      "891/891 [==============================] - 0s 241us/sample - loss: 0.1874\n",
      "Epoch 7/30\n",
      "891/891 [==============================] - 0s 264us/sample - loss: 0.1852\n",
      "Epoch 8/30\n",
      "891/891 [==============================] - 0s 222us/sample - loss: 0.1745\n",
      "Epoch 9/30\n",
      "891/891 [==============================] - 0s 222us/sample - loss: 0.1752\n",
      "Epoch 10/30\n",
      "891/891 [==============================] - 0s 245us/sample - loss: 0.1691\n",
      "Epoch 11/30\n",
      "891/891 [==============================] - 0s 201us/sample - loss: 0.1644\n",
      "Epoch 12/30\n",
      "891/891 [==============================] - 0s 163us/sample - loss: 0.1591\n",
      "Epoch 13/30\n",
      "891/891 [==============================] - 0s 198us/sample - loss: 0.1593\n",
      "Epoch 14/30\n",
      "891/891 [==============================] - 0s 223us/sample - loss: 0.1628\n",
      "Epoch 15/30\n",
      "891/891 [==============================] - 0s 232us/sample - loss: 0.1520\n",
      "Epoch 16/30\n",
      "891/891 [==============================] - 0s 207us/sample - loss: 0.1570\n",
      "Epoch 17/30\n",
      "891/891 [==============================] - 0s 241us/sample - loss: 0.1555\n",
      "Epoch 18/30\n",
      "891/891 [==============================] - 0s 198us/sample - loss: 0.1542\n",
      "Epoch 19/30\n",
      "891/891 [==============================] - 0s 229us/sample - loss: 0.1558\n",
      "Epoch 20/30\n",
      "891/891 [==============================] - 0s 241us/sample - loss: 0.1556\n",
      "Epoch 21/30\n",
      "891/891 [==============================] - 0s 199us/sample - loss: 0.1530\n",
      "Epoch 22/30\n",
      "891/891 [==============================] - 0s 198us/sample - loss: 0.1523\n",
      "Epoch 23/30\n",
      "891/891 [==============================] - 0s 219us/sample - loss: 0.1479\n",
      "Epoch 24/30\n",
      "891/891 [==============================] - 0s 224us/sample - loss: 0.1505\n",
      "Epoch 25/30\n",
      "891/891 [==============================] - 0s 226us/sample - loss: 0.1511\n",
      "Epoch 26/30\n",
      "891/891 [==============================] - 0s 177us/sample - loss: 0.1515\n",
      "Epoch 27/30\n",
      "891/891 [==============================] - 0s 206us/sample - loss: 0.1519\n",
      "Epoch 28/30\n",
      "891/891 [==============================] - 0s 185us/sample - loss: 0.1472\n",
      "Epoch 29/30\n",
      "891/891 [==============================] - 0s 170us/sample - loss: 0.1477\n",
      "Epoch 30/30\n",
      "891/891 [==============================] - 0s 165us/sample - loss: 0.1495\n",
      "(891, 7) (891, 2)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "model.fit(train_x, train_y, epochs=EPOCHS)\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making predictions using the model\n",
    "We can now use our trained model to make predictions about the **testing data**. We first need to load this data and reshape it as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Loading and reshaping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "As you can see, we have 418 entries to make predictions on, each containing 11 datapoints. Let's reshape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.3792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>262.375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164.867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>211.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1     2  3  4        5  6\n",
       "0    3  0  34.5  0  0   7.8292  2\n",
       "1    3  1    47  1  0        7  1\n",
       "2    2  0    62  0  0   9.6875  2\n",
       "3    3  0    27  0  0   8.6625  1\n",
       "4    3  1    22  1  1  12.2875  1\n",
       "5    3  0    14  0  0    9.225  1\n",
       "6    3  1    30  0  0   7.6292  2\n",
       "7    2  0    26  1  1       29  1\n",
       "8    3  1    18  0  0   7.2292  0\n",
       "9    3  0    21  2  0    24.15  1\n",
       "10   3  0     0  0  0   7.8958  1\n",
       "11   1  0    46  0  0       26  1\n",
       "12   1  1    23  1  0  82.2667  1\n",
       "13   2  0    63  1  0       26  1\n",
       "14   1  1    47  1  0   61.175  1\n",
       "15   2  1    24  1  0  27.7208  0\n",
       "16   2  0    35  0  0    12.35  2\n",
       "17   3  0    21  0  0    7.225  0\n",
       "18   3  1    27  1  0    7.925  1\n",
       "19   3  1    45  0  0    7.225  0\n",
       "20   1  0    55  1  0     59.4  0\n",
       "21   3  0     9  0  1   3.1708  1\n",
       "22   1  1     0  0  0  31.6833  1\n",
       "23   1  0    21  0  1  61.3792  0\n",
       "24   1  1    48  1  3  262.375  0\n",
       "25   3  0    50  1  0     14.5  1\n",
       "26   1  1    22  0  1  61.9792  0\n",
       "27   3  0  22.5  0  0    7.225  0\n",
       "28   1  0    41  0  0     30.5  1\n",
       "29   3  0     0  2  0  21.6792  0\n",
       "..  .. ..   ... .. ..      ... ..\n",
       "388  3  0    21  0  0     7.75  2\n",
       "389  3  0     6  3  1   21.075  1\n",
       "390  1  0    23  0  0     93.5  1\n",
       "391  1  1    51  0  1     39.4  1\n",
       "392  3  0    13  0  2    20.25  1\n",
       "393  2  0    47  0  0     10.5  1\n",
       "394  3  0    29  3  1   22.025  1\n",
       "395  1  1    18  1  0       60  1\n",
       "396  3  0    24  0  0     7.25  2\n",
       "397  1  1    48  1  1     79.2  0\n",
       "398  3  0    22  0  0    7.775  1\n",
       "399  3  0    31  0  0   7.7333  2\n",
       "400  1  1    30  0  0  164.867  1\n",
       "401  2  0    38  1  0       21  1\n",
       "402  1  1    22  0  1     59.4  0\n",
       "403  1  0    17  0  0     47.1  1\n",
       "404  1  0    43  1  0  27.7208  0\n",
       "405  2  0    20  0  0  13.8625  0\n",
       "406  2  0    23  1  0     10.5  1\n",
       "407  1  0    50  1  1    211.5  0\n",
       "408  3  1     0  0  0   7.7208  2\n",
       "409  3  1     3  1  1   13.775  1\n",
       "410  3  1     0  0  0     7.75  2\n",
       "411  1  1    37  1  0       90  2\n",
       "412  3  1    28  0  0    7.775  1\n",
       "413  3  0     0  0  0     8.05  1\n",
       "414  1  1    39  0  0    108.9  0\n",
       "415  3  0  38.5  0  0     7.25  1\n",
       "416  3  0     0  0  0     8.05  1\n",
       "417  3  0     0  1  1  22.3583  0\n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_data = np.array(test_df)\n",
    "test_data = reshape_data(test_data, \"test\")\n",
    "pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can see that the reshaping worked correctly and that we now have suitable data to make predictions on using our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for row in test_data:\n",
    "    prediction = model.predict(np.array([row]))\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking the predictions and calculating the accuracy\n",
    "Now that we have our predictions ready, we can see how well our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 418 Correct: 413 Incorrect: 5 Accuracy: 99.0%\n"
     ]
    }
   ],
   "source": [
    "test_output_df = pd.read_csv('gender_submission.csv')\n",
    "test_output = np.array(test_output_df)\n",
    "test_output = np.delete(test_output, [0], axis=1)\n",
    "test_output = np.concatenate(test_output)\n",
    "\n",
    "final_predictions = []\n",
    "for row in predictions:\n",
    "    prediction = row[0]\n",
    "    if len(prediction) >= 2:\n",
    "        if prediction[0] > prediction[1]:\n",
    "            final_predictions.append(1)\n",
    "        elif prediction[0] < prediction[1]:\n",
    "            final_predictions.append(0)\n",
    "        \n",
    "final_preditcions = np.array(final_predictions)\n",
    "\n",
    "# Check the overlap\n",
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(len(test_output)):\n",
    "    output = test_output[i]\n",
    "    prediction = final_predictions[i]\n",
    "    if prediction == output:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "accuracy = np.round(correct / len(final_predictions) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Total: {len(final_predictions)}\", f\"Correct: {correct}\", f\"Incorrect: {wrong}\", f\"Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**And there you go!** We have created a model that is accurate up to 94%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "Machine learning is a very powerful but complicated tool. It can be extremely useful for solving a large range of problems. Not to mention that it is a lot of fun to develop. Using A fairly simple NN we were able to predict with reasonable accuracy if a passenger on the Titanic was likely to survive or not. We used the power of `Python3` combined with `Numpy` to handle our data, the magic of `Matplotlib` to give us great insight into our dataset and the finesse of `Keras` and its linear algebra to construct a self-learning model that has come to know the ins and outs of this spectacular disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## References\n",
    "1. Wikipedia contributors. (2019a, 7 februari). Artificial neural network. Consulted on 7 februari 2019, at https://en.wikipedia.org/wiki/Artificial_neural_network\n",
    "2. Wikipedia contributors. (2019b, 3 februari). Softmax function - Wikipedia. Consulted on 7 februari 2019, at https://en.wikipedia.org/wiki/Softmax_function"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
